{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6e273f",
   "metadata": {},
   "source": [
    "# 1. Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7fde07f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_9180/1329681016.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import selenium\n",
    "from  selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get(\"https://www.amazon.in\")\n",
    "driver.implicitly_wait(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9fa1d2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter product you want to search: laptop\n"
     ]
    }
   ],
   "source": [
    "user_input=input(\"Enter product you want to search: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84932419",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box=driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "search_box.clear()\n",
    "search_box.send_keys(user_input)\n",
    "search_btn=driver.find_element(By.ID,\"nav-search-submit-button\").click() \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87c52f7",
   "metadata": {},
   "source": [
    "### 2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8202fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_names=[]\n",
    "product_name=[]\n",
    "product_price=[]\n",
    "exchange=[]\n",
    "delivery=[]\n",
    "availabilty=[]\n",
    "product_url=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bd4f3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "330f6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_class='a-size-medium a-color-base a-text-normal'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ac1f8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1\n",
      "scraping page 2\n",
      "scraping page 3\n"
     ]
    }
   ],
   "source": [
    "#scrap products from amazon\n",
    "product_name=[]\n",
    "for i in range(3):\n",
    "    print('scraping page',i+1)\n",
    "    name=driver.find_elements(By.XPATH, \"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "    for p in name:\n",
    "        product_name.append(p.text)\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[contains(text(), \"Next\")]').click()\n",
    "driver.implicitly_wait(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "adaa93da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54dc41b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASUS VivoBook 14 (2021), 14\" (35.56 cm) FHD, Intel Core i3-1115G4 11th Gen, Thin and Light Laptop (8GB/1TB HDD + 256GB SSD/Windows 11/Office 2021/Integrated Graphics/Silver/1.6 Kg), X415EA-EK372WS',\n",
       " 'Dell Vostro 3420 Laptop, Intel i5-1135G7, 8GB DDR4 & 512GB SSD, Win 11 + MSO\\'21, 14.0\" (35.56Cms) FHD WVA AG 250 nits, Carbon Black (D552281WIN9BE, 1.48Kgs)',\n",
       " 'ASUS VivoBook 14 (2021), Intel Core i5-1035G1 11th Gen, 14-inch (35.56 cms) FHD Thin and Light Laptop (8GB/512GB SSD/Office 2021/Windows 11/Integrated Graphics/Silver/1.6 Kg), X415JA-EB521WS',\n",
       " 'HP Pavilion x360,12th Gen Intel Core i5-1235U 8GB RAM/512GB SSD 14-inch(35.6 cm) FHD,multitouch-Enabled,Micro-Edge Display/Intel Iris Xe Graphics/Backlit KB/B&O/Win 11/MSO 2021/1.41 Kg, 14-ek0084TU',\n",
       " 'Dell Vostro 3400 14\" FHD i3-1115G4 / 8GB / 1TB HDD / Integrated Graphics / Windows 11 HSL + MS-Office / Black 1.7kgs/1 Year Onsite Warranty']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_name[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandname=[]\n",
    "productname=[]\n",
    "rating=[]\n",
    "numberrating=[]\n",
    "price=[]\n",
    "exchange=[]\n",
    "expected=[]\n",
    "availability=[]\n",
    "url=[]\n",
    "for i in url1:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        brandname.append(driver.find_element_by_xpath(\"//table[@class='a-keyvalue prodDetTable']/tbody/tr[10]\").text)\n",
    "    except NoSuchElementException:\n",
    "        brandname.append('-')\n",
    "    try:\n",
    "        productname.append(driver.find_element_by_xpath(\"//h1[@class='a-size-large a-spacing-none']\").text)\n",
    "    except NoSuchElementException:\n",
    "        productname.append('-')\n",
    "    try:\n",
    "        rating.append(driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\").text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append('-')\n",
    "    try:\n",
    "        numberrating.append(driver.find_element_by_id(\"acrCustomerReviewText\").text)\n",
    "    except NoSuchElementException:\n",
    "        numberrating.append('-')\n",
    "    try:\n",
    "        price.append(driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-price priceBlockBuyingPriceString']\").text)\n",
    "    except NoSuchElementException:\n",
    "        price.append('-')\n",
    "    try:\n",
    "        exchange.append(driver.find_element_by_xpath(\"//a[@class='a-size-small a-link-normal a-text-normal']\").text)\n",
    "    except NoSuchElementException:\n",
    "        exchange.append(\"-\")\n",
    "    try:\n",
    "        expected.append(driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-mini']/b\").text)\n",
    "    except NoSuchElementException:\n",
    "        expected.append('-')\n",
    "    try:\n",
    "        availability.append(driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-success']\").text)\n",
    "    except NoSuchElementException:\n",
    "        availability.append('-')\n",
    "    url.append(i)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93424d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({})\n",
    "df['brandname']=brandname\n",
    "df['productname']=productname\n",
    "df['rating']=rating\n",
    "df['numberrating']=numberrating\n",
    "df['price']=price\n",
    "df['exchange']=exchange\n",
    "df['expected']=expected\n",
    "df['availability']=availability\n",
    "df['url']=url\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ef112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brandname']=df['brandname'].apply(lambda x:x.replace('Manufacturer',''))\n",
    "df['rating']=df['rating'].apply(lambda x:x.split(' ')[0])\n",
    "df['numberrating']=df['numberrating'].apply(lambda x:x.split(' ')[0])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f9c3ea",
   "metadata": {},
   "source": [
    "### 3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfcc56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "url='https://images.google.com/?gws_rd=ssl'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "input1=driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\")\n",
    "input1.send_keys(\"fruits\")\n",
    "driver.find_element_by_xpath(\"//button[@class='Tg7LZd']\").click()\n",
    "for i in range(1000):\n",
    "    driver.execute_script(\"window.scrollBy(0,10000)\")\n",
    "fruit_url=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='bRMDJf islir']/img\"):\n",
    "        x=i.get_attribute(\"src\")\n",
    "        if x is not None:\n",
    "            if(x[0:4] == 'http'):\n",
    "                fruit_url.append(x)\n",
    "driver.find_element_by_xpath(\"//input[@class='og3lId']\").clear()\n",
    "driver.find_element_by_xpath(\"//input[@class='og3lId']\").send_keys(\"cars\")\n",
    "driver.find_element_by_xpath(\"//div[@class='XZ5MVe']\").click()\n",
    "for i in range(1000):\n",
    "    driver.execute_script(\"window.scrollBy(0,10000)\")\n",
    "car_url=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='bRMDJf islir']/img\"):\n",
    "        x=i.get_attribute(\"src\")\n",
    "        if x is not None:\n",
    "            if(x[0:4] == 'http'):\n",
    "                car_url.append(x)\n",
    "driver.find_element_by_xpath(\"//input[@class='og3lId']\").clear()\n",
    "driver.find_element_by_xpath(\"//input[@class='og3lId']\").send_keys(\"machine learning\")\n",
    "driver.find_element_by_xpath(\"//span[@class='n6h3Rc']\").click()\n",
    "for i in range(1000):\n",
    "    driver.execute_script(\"window.scrollBy(0,10000)\")\n",
    "ml_url=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='bRMDJf islir']/img\"):\n",
    "    x=i.get_attribute(\"src\")\n",
    "    if x is not None:\n",
    "        if(x[0:4]=='http'):\n",
    "            ml_url.append(x)\n",
    "df=pd.DataFrame({})\n",
    "df['Fruits']=fruit_url[0:100]\n",
    "df['Cars']=car_url[0:100]\n",
    "df['Machine learning']=ml_url[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736827ab",
   "metadata": {},
   "source": [
    "#### 4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0080892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "driver.find_element_by_xpath(\"//input[@class='_3704LK']\").send_keys(\"pixel 4A\")\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='_1fQZEK']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "smartphonename=[]\n",
    "color=[]\n",
    "ram=[]\n",
    "rom=[]\n",
    "displaysize=[]\n",
    "displayresolution=[]\n",
    "primarycamera=[]\n",
    "secondarycamera=[]\n",
    "processor=[]\n",
    "processorcore=[]\n",
    "battery=[]\n",
    "price=[]\n",
    "url=[]\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _1FH0tX']\").click()\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        smartphonename.append(driver.find_element_by_xpath(\"//span[@class='B_NuCI']\").text)\n",
    "    except NoSuchElementException:\n",
    "        smartphonename.append('-')\n",
    "    try:\n",
    "        color.append(driver.find_element_by_xpath(\"//div[@class='_3k-BhJ']/table/tbody/tr[4]/td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        color.append('-')\n",
    "    try:\n",
    "        ram.append(driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[4]/table/tbody/tr[2]/td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        ram.append('-')\n",
    "    try:\n",
    "        rom.append(driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[4]/table/tbody/tr[1]/td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        rom.append('-')\n",
    "    try:\n",
    "        displaysize.append(driver.find_element_by_xpath(\"//div[@class='_1UhVsV']/div[2]/table/tbody/tr/td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        displaysize.append('-')\n",
    "    try:\n",
    "        primarycamera.append(driver.find_element_by_xpath(\"//div[@class='_3k-BhJ'][5]/table/tbody/tr[2]/td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        primarycamera.append('-')\n",
    "    try:\n",
    "        secondarycamera.append(driver.find_element_by_xpath(\"//div[@class='_3k-BhJ'][5]/table/tbody/tr[5]/td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        secondarycamera.append('-')\n",
    "    try:\n",
    "        displayresolution.append(driver.find_element_by_xpath(\"//div[@class='_3k-BhJ'][2]/table/tbody/tr[2]/td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        displayresolution.append('-')\n",
    "    try:\n",
    "        processor.append(driver.find_element_by_xpath(\"//div[@class='_3k-BhJ'][3]/table/tbody/tr[2]/td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        processor.append('-')\n",
    "    try:\n",
    "        processorcore.append(driver.find_element_by_xpath(\"//div[@class='_3k-BhJ'][3]/table/tbody/tr[3]/td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        processorcore.append('-')\n",
    "    try:\n",
    "        battery.append(driver.find_element_by_xpath(\"//div[@class='_3k-BhJ'][9]/table/tbody/tr/td[2]\").text)\n",
    "    except NoSuchElementException:\n",
    "        battery.append('-')\n",
    "    try:\n",
    "        price.append(driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\").text)\n",
    "    except NoSuchElementException:\n",
    "        price.append('-')\n",
    "    url.append(i)\n",
    "df=pd.DataFrame({})\n",
    "df['smartphonename']=smartphonename\n",
    "df['color']=color\n",
    "df['ram']=ram\n",
    "df['rom']=rom\n",
    "df['displaysize']=displaysize\n",
    "df['displayresolution']=displayresolution\n",
    "df['primarycamera']=primarycamera\n",
    "df['secondarycamera']=secondarycamera\n",
    "df['processor']=processor\n",
    "df['processorcore']=processorcore\n",
    "df['battery']=battery\n",
    "df['price']=price\n",
    "df['url']=url\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f091b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['smartphonename']=df['smartphonename'].apply(lambda x:x.split('(')[0])\n",
    "df['primarycamera']=df['primarycamera'].apply(lambda x:x.split(' ')[0])\n",
    "df['secondarycamera']=df['secondarycamera'].apply(lambda x:x.split(' ')[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd36ca1",
   "metadata": {},
   "source": [
    "#### 5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab9007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import time\n",
    "from selenium import webdriver\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.get(\"https://www.google.com/maps\")\n",
    "time.sleep(5)\n",
    "location=driver.find_element_by_xpath(\"//input[@class='tactile-searchbox-input']\")\n",
    "input1=input(\"enter location:\")\n",
    "location.send_keys(input1)\n",
    "time.sleep(5)\n",
    "driver.find_element_by_id(\"searchbox-searchbutton\").click()\n",
    "time.sleep(5)\n",
    "url=driver.current_url\n",
    "x=url.split('@')[-1]\n",
    "x=x.split('/')[0]\n",
    "lat=x.split(',')[0]\n",
    "long=x.split(',')[1]\n",
    "print(\"Latitude:\",lat,\"Longitude:\",long)\n",
    "enter location:chennai\n",
    "Latitude: 13.0473748 Longitude: 79.9288011\n",
    "Write a program to scrap details of all the funding deals for second quarter (i.e. July 20 – September 20) from trak.in.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url='https://trak.in/india-startup-funding-investment-2015/'\n",
    "page=requests.get(url)\n",
    "soup=BeautifulSoup(page.content)\n",
    "Date=[]\n",
    "Startup=[]\n",
    "Industry=[]\n",
    "Subvertical=[]\n",
    "City=[]\n",
    "Investor=[]\n",
    "Investment=[]\n",
    "Amount=[]\n",
    "for p in soup.find_all(\"td\",class_='column-2'):\n",
    "    Date.append(p.text)\n",
    "for s in soup.find_all(\"td\",class_='column-3'):\n",
    "    Startup.append(s.text)\n",
    "for o in soup.find_all(\"td\",class_='column-4'):\n",
    "    Industry.append(o.text)\n",
    "for i in soup.find_all(\"td\",class_='column-5'):\n",
    "    Subvertical.append(i.text)\n",
    "for j in soup.find_all(\"td\",class_='column-6'):\n",
    "    City.append(j.text)\n",
    "for k in soup.find_all(\"td\",class_='column-7'):\n",
    "    Investor.append(k.text)\n",
    "for l in soup.find_all(\"td\",class_='column-8'):\n",
    "    Investment.append(l.text)\n",
    "for m in soup.find_all(\"td\",class_='column-9'):\n",
    "    Amount.append(m.text)\n",
    "df=pd.DataFrame({})\n",
    "df['Date']=Date\n",
    "df['StartUp']=Startup\n",
    "df['Industry']=Industry\n",
    "df['Subvertical']=Subvertical\n",
    "df['City']=City\n",
    "df['Investor']=Investor\n",
    "df['Investment Type']=Investment\n",
    "df['Amount']=Amount\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256a286",
   "metadata": {},
   "source": [
    "#### 6. Write a program to scrap details of all the funding deals for second quarter (i.e Jan 21 – March 21) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import time\n",
    "from selenium import webdriver\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.get(\"https://www.trak.in/\")\n",
    "time.sleep(3)\n",
    "x=driver.find_element_by_xpath(\"//li[@class='menu-have-icon menu-icon-type-fontawesome menu-item menu-item-type-post_type menu-item-object-page better-anim-fade menu-item-51510']/a\")\n",
    "y=x.get_attribute(\"href\")\n",
    "driver.get(y)#taking website url to funding dea\n",
    "Date=[]\n",
    "Startup=[]\n",
    "Industry=[]\n",
    "Subvertical=[]\n",
    "City=[]\n",
    "Investor=[]\n",
    "Investment=[]\n",
    "Amount=[]\n",
    "for i in driver.find_elements_by_xpath(\"//td[@class='column-2']\"):\n",
    "    Date.append(i.text)\n",
    "for j in driver.find_elements_by_xpath(\"//td[@class='column-3']\"):\n",
    "    Startup.append(j.text)\n",
    "for k in driver.find_elements_by_xpath(\"//td[@class='column-4']\"):\n",
    "    Industry.append(k.text)\n",
    "for l in driver.find_elements_by_xpath(\"//td[@class='column-5']\"):\n",
    "    Subvertical.append(l.text)\n",
    "for m in driver.find_elements_by_xpath(\"//td[@class='column-6']\"):\n",
    "    City.append(m.text)\n",
    "for n in driver.find_elements_by_xpath(\"//td[@class='column-7']\"):\n",
    "    Investor.append(n.text)\n",
    "for o in driver.find_elements_by_xpath(\"//td[@class='column-8']\"):\n",
    "    Investment.append(o.text)\n",
    "for p in driver.find_elements_by_xpath(\"//td[@class='column-9']\"):\n",
    "    Amount.append(p.text)\n",
    "#making dataframe \n",
    "import pandas as pd\n",
    "df=pd.DataFrame({})\n",
    "df['Date']=Date\n",
    "df['StartUp']=Startup\n",
    "df['Industry']=Industry\n",
    "df['Subvertical']=Subvertical\n",
    "df['City']=City\n",
    "df['Investor']=Investor\n",
    "df['Investment Type']=Investment\n",
    "df['Amount']=Amount\n",
    "df=df.loc[57:89]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f548aa",
   "metadata": {},
   "source": [
    "#### 7. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import time\n",
    "from selenium import webdriver\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.get(\"https://www.digit.in/\")\n",
    "#taking url to top 10 gaming laptops\n",
    "driver.find_element_by_xpath(\"//div[@class='listing_container']/ul/li[9]/a\").click()\n",
    "driver.find_element_by_xpath(\"//div[@class='Listbrand']/ul/li[2]/a\").click()                                  \n",
    "                           \n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='right-container']/div/a\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "laptopname=[]\n",
    "releasedate=[]\n",
    "os=[]\n",
    "display=[]\n",
    "processor=[]\n",
    "memory=[]\n",
    "price=[]\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        laptopname.append(driver.find_element_by_xpath(\"//div[@class='heading-wraper']/h1\").text)\n",
    "    except NoSuchElementException:\n",
    "        laptopname.append('-')\n",
    "    try:\n",
    "        releasedate.append(driver.find_element_by_xpath(\"//div[@class='status-bar only-desktop']/div[2]/b\").text)\n",
    "    except NoSuchElementException:\n",
    "        releasedate.append('-')\n",
    "    try:\n",
    "        os.append(driver.find_element_by_xpath(\"//div[@class='value']\").text)\n",
    "    except NoSuchElementException:\n",
    "        os.append('-')\n",
    "    try:\n",
    "        display.append(driver.find_element_by_xpath(\"//div[@class='Specs-Wrap  notspecs ']/ul/li[2]/div\").text)\n",
    "    except NoSuchElementException:\n",
    "        display.append('-')\n",
    "    try:\n",
    "        processor.append(driver.find_element_by_xpath(\"//div[@class='Specs-Wrap  notspecs ']/ul/li[3]/div\").text)\n",
    "    except NoSuchElementException:\n",
    "        processor.append('-')\n",
    "    try:\n",
    "        memory.append(driver.find_element_by_xpath(\"//div[@class='Specs-Wrap  notspecs ']/ul/li[4]/div\").text)\n",
    "    except NoSuchElementException:\n",
    "        memory.append('-')\n",
    "    try:\n",
    "        price.append(driver.find_element_by_xpath(\"//div[@class='Block-price']/b\").text)\n",
    "    except NoSuchElementException:\n",
    "        price.append('-')\n",
    "                          \n",
    "import pandas as pd\n",
    "df=pd.DataFrame({})\n",
    "df['laptopname']=laptopname\n",
    "df['releasedate']=releasedate\n",
    "df['os']=os\n",
    "df['display']=display\n",
    "df['processor']=processor\n",
    "df['memory']=memory\n",
    "df['price']=price\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
